import pandas as pd
import re
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
import numpy as np

# ç¡®ä¿å·²å®‰è£…æ‰€éœ€åº“: pip install pandas scikit-learn sentence-transformers torch
from sentence_transformers import SentenceTransformer

# --- æ–‡ä»¶è®¾ç½® ---
# è¾“å…¥æ–‡ä»¶æ˜¯ä¸Šä¸€æ­¥æ¸…ç†äº†ç¿»è¯‘æ–‡æœ¬åçš„æ–‡ä»¶
input_filename = 'Google-Maps-Reviews_cleaned.csv'                  
# è¾“å‡ºæ–‡ä»¶å°†æ˜¯æœ€ç»ˆå¯ç”¨äºæœºå™¨å­¦ä¹ çš„çº¯æ•°å­—ç‰¹å¾æ–‡ä»¶
output_features_filename = 'Google-Maps-Reviews_features_engineered.csv'

try:
    # --- 1. åŠ è½½æ•°æ® ---
    df = pd.read_csv(input_filename, encoding='utf-8-sig')
    print("æˆåŠŸåŠ è½½æ•°æ®ã€‚åŸå§‹æ•°æ®å½¢çŠ¶:", df.shape)
    print("-" * 40)

    # --- 2. å¸ƒå°”å‹ç‰¹å¾å¤„ç† ---
    print("æ­¥éª¤ 1/4: å¤„ç†å¸ƒå°”å‹ç‰¹å¾...")
    df['isAdvertisement'] = df['isAdvertisement'].astype(bool).astype(int)
    df['isLocalGuide'] = df['isLocalGuide'].astype(bool).astype(int)
    print("å®Œæˆã€‚")
    print("-" * 40)

    # --- 3. æ•°å€¼å‹ç‰¹å¾å¤„ç† ---
    print("æ­¥éª¤ 2/4: å¤„ç†æ•°å€¼å‹ç‰¹å¾...")
    numeric_cols = ['reviewerNumberOfReviews', 'reviewsCount', 'stars', 'place_totalScore']
    imputer = SimpleImputer(strategy='median')
    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])
    scaler = StandardScaler()
    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
    print("å®Œæˆç¼ºå¤±å€¼å¡«å……å’Œæ ‡å‡†åŒ–ã€‚")
    print("-" * 40)

    # --- 4. åˆ†ç±»ç‰¹å¾å¤„ç† ---
    print("æ­¥éª¤ 3/4: å¤„ç†åˆ†ç±»ç‰¹å¾ (One-Hot Encoding)...")
    categorical_cols = ['class_both', 'place_title']
    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
    encoded_features = ohe.fit_transform(df[categorical_cols])
    new_col_names = ohe.get_feature_names_out(categorical_cols)
    encoded_df = pd.DataFrame(encoded_features, columns=new_col_names, index=df.index)
    df = pd.concat([df, encoded_df], axis=1)
    df.drop(columns=categorical_cols, inplace=True)
    print(f"å®Œæˆã€‚å·²ç”Ÿæˆ {encoded_df.shape[1]} ä¸ªæ–°ç‰¹å¾åˆ—ã€‚")
    print("-" * 40)
    
    # --- 5. æ–‡æœ¬ç‰¹å¾å¤„ç† ---
    print("æ­¥éª¤ 4/4: å¤„ç†æ–‡æœ¬ç‰¹å¾ (æ¸…æ´—ä¸å‘é‡åŒ–)...")

    # æ­¥éª¤ 5.1: æ–‡æœ¬æ¸…æ´—
    def clean_text(text):
        if not isinstance(text, str):
            return ""
        text = text.lower()
        text = re.sub(r'<.*?>', '', text)
        text = re.sub(r'[^a-z0-9\s]', '', text) # ä¿ç•™å­—æ¯å’Œæ•°å­—
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    # æ¸…æ´— 'review_text' åˆ—ï¼Œå¹¶ç¡®ä¿æ²¡æœ‰ç©ºå€¼
    df['review_text_cleaned'] = df['review_text'].fillna('').apply(clean_text)
    print("æ–‡æœ¬æ¸…æ´—å®Œæˆã€‚")

    # æ­¥éª¤ 5.2: ä½¿ç”¨Sentence-Transformerè¿›è¡Œå¥å­åµŒå…¥
    print("\næ­£åœ¨åŠ è½½Sentence-Transformeræ¨¡å‹... (é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·ç¨å€™)")
    # æˆ‘ä»¬é€‰ç”¨ä¸€ä¸ªåœ¨æ€§èƒ½å’Œé€Ÿåº¦ä¸Šè¡¨ç°éƒ½éå¸¸å‡ºè‰²çš„é€šç”¨æ¨¡å‹
    model = SentenceTransformer('all-MiniLM-L6-v2')
    
    # å‡†å¤‡è¦ç¼–ç çš„å¥å­åˆ—è¡¨
    sentences_to_encode = df['review_text_cleaned'].tolist()
    
    print("\næ­£åœ¨ç”Ÿæˆå¥å­å‘é‡... (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œå–å†³äºæ‚¨çš„CPUæ€§èƒ½)")
    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œç¼–ç ï¼Œshow_progress_bar=True å¯ä»¥æ˜¾ç¤ºè¿›åº¦æ¡
    sentence_embeddings = model.encode(sentences_to_encode, show_progress_bar=True)
    print("å¥å­å‘é‡ç”Ÿæˆå®Œæ¯•ï¼å‘é‡ç»´åº¦:", sentence_embeddings.shape)

    # æ­¥éª¤ 5.3: å°†å‘é‡æ•´åˆå›DataFrame
    # åˆ›å»ºä¸€ä¸ªåŒ…å«åµŒå…¥å‘é‡çš„æ–°DataFrame
    embedding_cols = [f'embedding_{i}' for i in range(sentence_embeddings.shape[1])]
    embedding_df = pd.DataFrame(sentence_embeddings, columns=embedding_cols, index=df.index)
    
    # å°†æ–°ç¼–ç çš„åˆ—ä¸ä¸»DataFrameåˆå¹¶
    df = pd.concat([df, embedding_df], axis=1)
    print("å·²å°†æ–‡æœ¬å‘é‡åˆå¹¶åˆ°ä¸»æ•°æ®æ¡†ã€‚")

    # --- 6. æœ€ç»ˆæ¸…ç†å’Œä¿å­˜ ---
    # åˆ é™¤åŸå§‹æ–‡æœ¬åˆ—å’Œæ¸…æ´—åçš„æ–‡æœ¬åˆ—ï¼Œå› ä¸ºå®ƒä»¬çš„ä¿¡æ¯å·²è¢«å‘é‡æ•è·
    df.drop(columns=['review_text', 'review_text_cleaned', 'name'], inplace=True)
    print("\nå·²åˆ é™¤åŸå§‹æ–‡æœ¬åˆ—ï¼Œç”Ÿæˆæœ€ç»ˆçš„çº¯æ•°å­—ç‰¹å¾çŸ©é˜µã€‚")

    # ä¿å­˜æœ€ç»ˆçš„ã€å¯ç”¨äºæœºå™¨å­¦ä¹ çš„ç‰¹å¾æ–‡ä»¶
    df.to_csv(output_features_filename, index=False, encoding='utf-8-sig')
    print("-" * 40)
    print(f"ğŸ‰ æ‰€æœ‰é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹å®Œæˆï¼æœ€ç»ˆæ–‡ä»¶å·²ä¿å­˜ä¸º '{output_features_filename}'ã€‚")
    print("æœ€ç»ˆæ•°æ®å½¢çŠ¶:", df.shape)


except FileNotFoundError:
    print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ '{input_filename}'ã€‚è¯·ç¡®ä¿è„šæœ¬å’Œå¤„ç†å¥½çš„CSVæ–‡ä»¶åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹ã€‚")
except Exception as e:
    print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{e}")